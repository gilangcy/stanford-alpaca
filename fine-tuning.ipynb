{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Preprocess Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:11:32.157947Z","iopub.status.busy":"2023-10-13T02:11:32.157090Z","iopub.status.idle":"2023-10-13T02:11:42.652458Z","shell.execute_reply":"2023-10-13T02:11:42.650891Z","shell.execute_reply.started":"2023-10-13T02:11:32.157901Z"},"trusted":true},"outputs":[],"source":["!pip install gdown\n","!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gdown\n","\n","url = \"https://drive.google.com/drive/folders/1KLzX-PB_1SeufhlLrrGrArDw21F2KMgT\"\n","gdown.download_folder(url, quiet=True, use_cookies=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:25.906290Z","iopub.status.busy":"2023-10-13T02:14:25.905897Z","iopub.status.idle":"2023-10-13T02:14:27.030834Z","shell.execute_reply":"2023-10-13T02:14:27.029401Z","shell.execute_reply.started":"2023-10-13T02:14:25.906257Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["batch1\tbatch10  batch2  batch3  batch4  batch5  batch6  batch7  batch8  batch9\n"]}],"source":["%cd manual_reviewed\n","!dir\n","!rm batch1\n","!mv batch1s batch1\n","!dir"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:49:42.345598Z","iopub.status.busy":"2023-10-13T03:49:42.345080Z","iopub.status.idle":"2023-10-13T03:49:44.917072Z","shell.execute_reply":"2023-10-13T03:49:44.915844Z","shell.execute_reply.started":"2023-10-13T03:49:42.345558Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>instruction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dokter, aku mengalami serangan panik tiba-tiba...</td>\n","      <td>Berdasarkan apa yang Anda katakan, sepertinya ...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dokter, aku sudah beberapa minggu ini mengalam...</td>\n","      <td>Anda mungkin memiliki polip tali suara. Untuk ...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Halo, Dokter, aku mungkin memiliki sindrom Tur...</td>\n","      <td>Oke, dalam hal itu, Anda perlu menjalani pemer...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dokter, aku mengalami kondisi yang disebut kri...</td>\n","      <td>Anda harus menjalani pemeriksaan kulit fisik l...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dokter, aku pikir aku telah diracuni. Aku tida...</td>\n","      <td>Maaf mendengar itu. Kita perlu melakukan beber...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>Dokter, aku sering buang air kecil, gatal vagi...</td>\n","      <td>Berdasarkan gejala Anda, tampaknya Anda mungki...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>Aku punya banyak masalah dengan buang air keci...</td>\n","      <td>Gejala ini bisa disebabkan oleh Human Papillom...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>Dokter, aku mengalami buang air kecil, buang a...</td>\n","      <td>Berdasarkan gejala Anda, kemungkinan Anda memi...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>Hei dokter, aku mengalami sakit lengan, sakit ...</td>\n","      <td>Berdasarkan gejala Anda, mungkin Anda memiliki...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>Dokter, aku mengalami beberapa ledakan panas, ...</td>\n","      <td>Berdasarkan gejala Anda, mungkin Anda mengalam...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                  input  \\\n","0     Dokter, aku mengalami serangan panik tiba-tiba...   \n","1     Dokter, aku sudah beberapa minggu ini mengalam...   \n","2     Halo, Dokter, aku mungkin memiliki sindrom Tur...   \n","3     Dokter, aku mengalami kondisi yang disebut kri...   \n","4     Dokter, aku pikir aku telah diracuni. Aku tida...   \n","...                                                 ...   \n","4995  Dokter, aku sering buang air kecil, gatal vagi...   \n","4996  Aku punya banyak masalah dengan buang air keci...   \n","4997  Dokter, aku mengalami buang air kecil, buang a...   \n","4998  Hei dokter, aku mengalami sakit lengan, sakit ...   \n","4999  Dokter, aku mengalami beberapa ledakan panas, ...   \n","\n","                                                 output  \\\n","0     Berdasarkan apa yang Anda katakan, sepertinya ...   \n","1     Anda mungkin memiliki polip tali suara. Untuk ...   \n","2     Oke, dalam hal itu, Anda perlu menjalani pemer...   \n","3     Anda harus menjalani pemeriksaan kulit fisik l...   \n","4     Maaf mendengar itu. Kita perlu melakukan beber...   \n","...                                                 ...   \n","4995  Berdasarkan gejala Anda, tampaknya Anda mungki...   \n","4996  Gejala ini bisa disebabkan oleh Human Papillom...   \n","4997  Berdasarkan gejala Anda, kemungkinan Anda memi...   \n","4998  Berdasarkan gejala Anda, mungkin Anda memiliki...   \n","4999  Berdasarkan gejala Anda, mungkin Anda mengalam...   \n","\n","                                            instruction  \n","0     Jika Anda seorang dokter, silakan menjawab per...  \n","1     Jika Anda seorang dokter, silakan menjawab per...  \n","2     Jika Anda seorang dokter, silakan menjawab per...  \n","3     Jika Anda seorang dokter, silakan menjawab per...  \n","4     Jika Anda seorang dokter, silakan menjawab per...  \n","...                                                 ...  \n","4995  Jika Anda seorang dokter, silakan menjawab per...  \n","4996  Jika Anda seorang dokter, silakan menjawab per...  \n","4997  Jika Anda seorang dokter, silakan menjawab per...  \n","4998  Jika Anda seorang dokter, silakan menjawab per...  \n","4999  Jika Anda seorang dokter, silakan menjawab per...  \n","\n","[5000 rows x 3 columns]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","df = pd.DataFrame()\n","\n","for i in range(10):\n","    inp = pd.read_excel(f'batch{i+1}', usecols=['input', 'output', 'instruction'])\n","    df = pd.concat([df, inp])\n","\n","df = df.reset_index(drop=True)[['input', 'output', 'instruction']]\n","df"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:50:13.526098Z","iopub.status.busy":"2023-10-13T03:50:13.525602Z","iopub.status.idle":"2023-10-13T03:50:13.535213Z","shell.execute_reply":"2023-10-13T03:50:13.533877Z","shell.execute_reply.started":"2023-10-13T03:50:13.526061Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"input\":\"Dokter, aku mengalami serangan panik tiba-tiba dan sering.\",\"output\":\"Berdasarkan apa yang Anda katakan, sepertinya Anda mungkin menderita gangguan panik. Langkah terbaik adalah memulai dengan psikoterapi dan konseling kesehatan mental. Selain itu, kita harus melakukan elektrokardiogram untuk memastikan bahwa tidak ada masalah fisik yang menyebabkan serangan panik Anda. Kita juga perlu melakukan skrining depresi dan skrining toksikologi untuk mengesampingkan penyebab lain. Akhirnya, saya akan merekomendasikan evaluasi dan terapi psikologis dan psikiatri yang komprehensif untuk membantu mengelola gejala Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku sudah beberapa minggu ini mengalami suara serak dan tidak kunjung membaik meskipun sudah minum obat. Apa masalahnya?\",\"output\":\"Anda mungkin memiliki polip tali suara. Untuk mengkonfirmasi ini, kita perlu melakukan trakeoskopi dan laringoskopi dengan biopsi. Kita juga mungkin perlu melakukan penilaian terapi kerja seperti terapi pidato, prosedur diagnostik lainnya seperti wawancara atau konsultasi, latihan terapi fisik, serta prosedur diagnostik di hidung, mulut, dan pharynx Anda untuk mengesampingkan kondisi lain yang mendasari. Selain itu, kita mungkin perlu mengevaluasi mata dan telinga Anda untuk kondisi terkait, seperti diagnostik ophthalmologic dan otologic dan pengobatan.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Halo, Dokter, aku mungkin memiliki sindrom Turner.\",\"output\":\"Oke, dalam hal itu, Anda perlu menjalani pemeriksaan kulit fisik lengkap, ultrasonografi, dan beberapa prosedur diagnostik lainnya seperti wawancara, evaluasi, dan konsultasi. Selain itu, kita perlu melakukan ekokardiografi, memeriksa payudara Anda, dan memeriksa mata dan telinga Anda untuk masalah apa pun. Kami juga akan melakukan pemeriksaan depresi untuk menilai kesehatan mental Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku mengalami kondisi yang disebut kriptorkidisme. testisku tidak turun dengan benar ke dalam skrotum. Apa tes medis yang perlu aku lakukan?\",\"output\":\"Anda harus menjalani pemeriksaan kulit fisik lengkap untuk melihat sejauh mana testis yang tidak turun. Kemudian, kita perlu melakukan ultrasonografi untuk mengetahui lokasi testis yang tepat. Setelah itu, pemeriksaan panggul dan pemeriksaan rektum akan dilakukan untuk menentukan apakah testis telah turun ke wilayah panggul. Jika tidak, maka prosedur terapi OR lainnya yang terkait dengan prosedur alat kelamin pria atau sistem saraf mungkin diperlukan. Kami juga akan melakukan penilaian terapi kerja untuk menilai terapi pidato Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku pikir aku telah diracuni. Aku tidak sengaja meminum etilen glikol.\",\"output\":\"Maaf mendengar itu. Kita perlu melakukan beberapa tes untuk menentukan tingkat keracunan. Kita perlu memberikan penggantian cairan intravena untuk membantu mencuci racun. Kita juga perlu melakukan tes hematologis, tes toksikologi, dan jumlah darah lengkap untuk menilai kerusakan. Selain itu, kita perlu melakukan elektrokardiogram, mengukur kadar glukosa Anda dan memeriksa tingkat alkohol darah Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n"]}],"source":["for i in df.index[:5]:\n","    print(df.loc[i].to_json())\n","    print(type(df.loc[i].to_json()))"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:51:34.277967Z","iopub.status.busy":"2023-10-13T03:51:34.277479Z","iopub.status.idle":"2023-10-13T03:51:34.880947Z","shell.execute_reply":"2023-10-13T03:51:34.879777Z","shell.execute_reply.started":"2023-10-13T03:51:34.277934Z"},"trusted":true},"outputs":[],"source":["with open('allBatch.json', 'w') as f:\n","    for i in df.index:\n","        f.writelines(df.loc[i].to_json() + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-ca991695af4ec410/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9da9402ab93c4697a6e167f1fbdb67f5","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4aa2bf085be74b548a44d9bf68efb6af","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-ca991695af4ec410/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"170683d9abac42c6a92ff8d7abc57acf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'output', 'instruction'],\n","        num_rows: 5000\n","    })\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","# Adjust with your path\n","data = load_dataset(\"json\", data_files='/kaggle/input/allbatch/allBatch.json')\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0e8500647ca4e929481f2ea588ef6a8","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. LlaMa 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:24:53.156282Z","iopub.status.busy":"2023-10-16T01:24:53.155997Z","iopub.status.idle":"2023-10-16T01:25:42.340093Z","shell.execute_reply":"2023-10-16T01:25:42.338932Z","shell.execute_reply.started":"2023-10-16T01:24:53.156259Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-19T04:25:48.261940Z","iopub.status.busy":"2023-10-19T04:25:48.261699Z","iopub.status.idle":"2023-10-19T04:26:03.186601Z","shell.execute_reply":"2023-10-19T04:26:03.185859Z","shell.execute_reply.started":"2023-10-19T04:25:48.261919Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:26:20.896386Z","iopub.status.busy":"2023-10-16T01:26:20.894984Z","iopub.status.idle":"2023-10-16T01:30:00.927623Z","shell.execute_reply":"2023-10-16T01:30:00.926102Z","shell.execute_reply.started":"2023-10-16T01:26:20.896344Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5aec0134d844c3fae87597838b11b3e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efff25e0c4974260989bd8f496bdcc05","version_major":2,"version_minor":0},"text/plain":["Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23bfd7304b96431cbd207f84f24f3771","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71b20db883f34faea182a08358763d6c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c69c166c43b422cad9f38c036c835fb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b125824206c4d73a8f9be490068eed7","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7d2a6f250664bd2b4c6b1eb719e5481","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["base_model = 'meta-llama/Llama-2-7b-hf'\n","model = LlamaForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:00.931918Z","iopub.status.busy":"2023-10-16T01:30:00.931497Z","iopub.status.idle":"2023-10-16T01:30:01.442883Z","shell.execute_reply":"2023-10-16T01:30:01.441946Z","shell.execute_reply.started":"2023-10-16T01:30:00.931880Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ccc2d21b14546409adf22a1ed7d0e74","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59f441de57734e12bec5bf70d5f8b52c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e446d3d584664836b4225919b33af532","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = LlamaTokenizer.from_pretrained(base_model)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.445159Z","iopub.status.busy":"2023-10-16T01:30:01.444329Z","iopub.status.idle":"2023-10-16T01:30:01.449494Z","shell.execute_reply":"2023-10-16T01:30:01.448399Z","shell.execute_reply.started":"2023-10-16T01:30:01.445114Z"},"trusted":true},"outputs":[],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    get_peft_model_state_dict,\n","    prepare_model_for_int8_training\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.452470Z","iopub.status.busy":"2023-10-16T01:30:01.451841Z","iopub.status.idle":"2023-10-16T01:30:01.474831Z","shell.execute_reply":"2023-10-16T01:30:01.474037Z","shell.execute_reply.started":"2023-10-16T01:30:01.452438Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]}],"source":["model = prepare_model_for_int8_training(model)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.476354Z","iopub.status.busy":"2023-10-16T01:30:01.476063Z","iopub.status.idle":"2023-10-16T01:30:01.483061Z","shell.execute_reply":"2023-10-16T01:30:01.481617Z","shell.execute_reply.started":"2023-10-16T01:30:01.476327Z"},"trusted":true},"outputs":[],"source":["# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  target_modules=lora_target_modules,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.485272Z","iopub.status.busy":"2023-10-16T01:30:01.484596Z","iopub.status.idle":"2023-10-16T01:30:01.635870Z","shell.execute_reply":"2023-10-16T01:30:01.634925Z","shell.execute_reply.started":"2023-10-16T01:30:01.485239Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"]}],"source":["model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:21.970880Z","iopub.status.busy":"2023-10-20T01:53:21.970297Z","iopub.status.idle":"2023-10-20T01:53:21.980240Z","shell.execute_reply":"2023-10-20T01:53:21.979084Z","shell.execute_reply.started":"2023-10-20T01:53:21.970822Z"},"trusted":true},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  if label:\n","      res = '''<s>[INST] <<SYS>>\\n{0}\\n<</SYS>>\\n\\n{1} [/INST] {2} </s>'''.format(template['prompt_input'].format(instruction=instruction, input=input), template['response_split'], label)\n","  else:\n","      res = '''<s>[INST] <<SYS>>\\n{0}\\n<</SYS>>\\n\\n{1} [/INST]'''.format(template['prompt_input'].format(instruction=instruction, input=input), template['response_split'])\n","      \n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:24.647601Z","iopub.status.busy":"2023-10-20T01:53:24.647105Z","iopub.status.idle":"2023-10-20T01:53:31.515663Z","shell.execute_reply":"2023-10-20T01:53:31.514772Z","shell.execute_reply.started":"2023-10-20T01:53:24.647559Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:16.958032Z","iopub.status.busy":"2023-10-16T01:35:16.957669Z","iopub.status.idle":"2023-10-16T01:35:16.973450Z","shell.execute_reply":"2023-10-16T01:35:16.972446Z","shell.execute_reply.started":"2023-10-16T01:35:16.958006Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:20.430557Z","iopub.status.busy":"2023-10-16T01:35:20.430118Z","iopub.status.idle":"2023-10-16T01:35:20.439721Z","shell.execute_reply":"2023-10-16T01:35:20.438457Z","shell.execute_reply.started":"2023-10-16T01:35:20.430526Z"},"trusted":true},"outputs":[],"source":["model.config.use_cache = False\n","old_state_dict = model.state_dict\n","model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(model, type(model))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:24.349378Z","iopub.status.busy":"2023-10-16T01:35:24.349029Z","iopub.status.idle":"2023-10-16T07:36:00.092273Z","shell.execute_reply":"2023-10-16T07:36:00.091243Z","shell.execute_reply.started":"2023-10-16T01:35:24.349352Z"},"trusted":true},"outputs":[],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T07:40:32.041087Z","iopub.status.busy":"2023-10-16T07:40:32.040677Z","iopub.status.idle":"2023-10-16T07:40:32.892982Z","shell.execute_reply":"2023-10-16T07:40:32.891851Z","shell.execute_reply.started":"2023-10-16T07:40:32.041058Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eae36e01d3b5485f8bd7c7c9edea020e","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/Llama-2-7b-finetuned-2/commit/65144b5fae005bb987602fa9a6cf9102284a7271', commit_message='Upload model', commit_description='', oid='65144b5fae005bb987602fa9a6cf9102284a7271', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('Llama-2-7b-finetuned-2', safe_serialization=True)"]},{"cell_type":"markdown","metadata":{},"source":["# PolyLM"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:29:03.799964Z","iopub.status.busy":"2023-10-20T01:29:03.799292Z","iopub.status.idle":"2023-10-20T01:29:42.070857Z","shell.execute_reply":"2023-10-20T01:29:42.069976Z","shell.execute_reply.started":"2023-10-20T01:29:03.799939Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:43:13.460279Z","iopub.status.busy":"2023-10-18T06:43:13.459895Z","iopub.status.idle":"2023-10-18T06:44:04.773827Z","shell.execute_reply":"2023-10-18T06:44:04.769985Z","shell.execute_reply.started":"2023-10-18T06:43:13.460252Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"506a8dee9a124c81aeb48204eebbd0ef","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/766 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b491dbf8b1694751a2a6e59e0583aa35","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/3.68G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch\n","\n","base_model = 'DAMO-NLP-MT/polylm-1.7b'\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:44:04.778248Z","iopub.status.busy":"2023-10-18T06:44:04.777709Z","iopub.status.idle":"2023-10-18T06:44:06.658257Z","shell.execute_reply":"2023-10-18T06:44:06.657483Z","shell.execute_reply.started":"2023-10-18T06:44:04.778222Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d800a10f3f34a29be1042f58230ac7f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"233c480d39ea42c1ac8c185c17d58ab3","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/4.75M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"349cf06ee4fc4407ac2291ad737a13bc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:44:14.521776Z","iopub.status.busy":"2023-10-18T06:44:14.521206Z","iopub.status.idle":"2023-10-18T06:44:14.607042Z","shell.execute_reply":"2023-10-18T06:44:14.606294Z","shell.execute_reply.started":"2023-10-18T06:44:14.521749Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 1,572,864 || all params: 1,738,657,792 || trainable%: 0.09046426543723217\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]}],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training\n",")\n","\n","model = prepare_model_for_int8_training(model)\n","\n","# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n","\n","  if label:\n","      res = f\"{res} \\n\\n### Tanggapan:\\n{label}\"\n","\n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:45:17.061772Z","iopub.status.busy":"2023-10-18T06:45:17.061110Z","iopub.status.idle":"2023-10-18T06:45:17.078327Z","shell.execute_reply":"2023-10-18T06:45:17.077539Z","shell.execute_reply.started":"2023-10-18T06:45:17.061741Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:45:20.980715Z","iopub.status.busy":"2023-10-18T06:45:20.980358Z","iopub.status.idle":"2023-10-18T08:05:06.397778Z","shell.execute_reply":"2023-10-18T08:05:06.397103Z","shell.execute_reply.started":"2023-10-18T06:45:20.980688Z"},"trusted":true},"outputs":[],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T08:10:55.898499Z","iopub.status.busy":"2023-10-18T08:10:55.897824Z","iopub.status.idle":"2023-10-18T08:10:58.221243Z","shell.execute_reply":"2023-10-18T08:10:58.220612Z","shell.execute_reply.started":"2023-10-18T08:10:55.898468Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42a1e157511b4e569f821babc64fb102","version_major":2,"version_minor":0},"text/plain":["adapter_model.bin:   0%|          | 0.00/6.31M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/polylm-1.7b-finetuned/commit/5385485e8e489c405600862be285673f51cc3f0b', commit_message='Upload model', commit_description='', oid='5385485e8e489c405600862be285673f51cc3f0b', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('polylm-1.7b-finetuned')"]},{"cell_type":"markdown","metadata":{},"source":["# InternLM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:29:42.072688Z","iopub.status.busy":"2023-10-20T01:29:42.072425Z","iopub.status.idle":"2023-10-20T01:51:18.213140Z","shell.execute_reply":"2023-10-20T01:51:18.212381Z","shell.execute_reply.started":"2023-10-20T01:29:42.072663Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90292abace264fed9a521c9f10674dd2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ecefb177c4347b896331ada018d7602","version_major":2,"version_minor":0},"text/plain":["Downloading (…)guration_internlm.py:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- configuration_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba18541584d149f3985a514f9f5658f1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)modeling_internlm.py:   0%|          | 0.00/43.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- modeling_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"220bc725e99a452cadda39455ae8bd73","version_major":2,"version_minor":0},"text/plain":["Downloading (…)model.bin.index.json:   0%|          | 0.00/37.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6300c6a27752490297a3429d12000231","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b5baaa87aeb40e387ffbb2723812c6d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00001-of-00008.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5c6d9d76f424823babc200ba5037707","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00002-of-00008.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dca19a4c573a4ff78ebe92fd915797fd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00003-of-00008.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d9bc9e500a840dcacd595c01c8ee783","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00004-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f01901a07953472fa80a5c18896ec7db","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00005-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac30a5e5b9454decb4777eb55a386773","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00006-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"324bb0fd0580442eabb7d69860d15f5e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00007-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7597b88c09974cf9ab380ab10327be77","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00008-of-00008.bin:   0%|          | 0.00/845M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e0d791f4eca48cda7abce77c9ff7a5f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0b7dcc563df4f1aa7377fc77af02750","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch\n","\n","base_model = 'internlm/internlm-7b'\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:01.614177Z","iopub.status.busy":"2023-10-20T01:53:01.612774Z","iopub.status.idle":"2023-10-20T01:53:03.649251Z","shell.execute_reply":"2023-10-20T01:53:03.648520Z","shell.execute_reply.started":"2023-10-20T01:53:01.614143Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb1725fe02454277b95cbabf0a3c496b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/343 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ec1c659fe134e2f8b0434b4150114a3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)nization_internlm.py:   0%|          | 0.00/8.95k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- tokenization_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1152678963024ece91e933ec4edca8ec","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a87b5ece75f54646ae26ab473e1c0abd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:06.684764Z","iopub.status.busy":"2023-10-20T01:53:06.684433Z","iopub.status.idle":"2023-10-20T01:53:06.971209Z","shell.execute_reply":"2023-10-20T01:53:06.970385Z","shell.execute_reply.started":"2023-10-20T01:53:06.684739Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 4,194,304 || all params: 7,326,142,464 || trainable%: 0.05725119352524783\n"]}],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training\n",")\n","\n","model = prepare_model_for_int8_training(model)\n","\n","# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  target_modules=lora_target_modules,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n","\n","  if label:\n","      res = f\"{res} \\n\\n### Tanggapan:\\n{label}\"\n","\n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:47.033523Z","iopub.status.busy":"2023-10-20T01:53:47.032840Z","iopub.status.idle":"2023-10-20T01:53:47.067267Z","shell.execute_reply":"2023-10-20T01:53:47.066418Z","shell.execute_reply.started":"2023-10-20T01:53:47.033488Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:49.758885Z","iopub.status.busy":"2023-10-20T01:53:49.758080Z","iopub.status.idle":"2023-10-20T07:46:41.508183Z","shell.execute_reply":"2023-10-20T07:46:41.507245Z","shell.execute_reply.started":"2023-10-20T01:53:49.758853Z"},"trusted":true},"outputs":[],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T07:58:10.972856Z","iopub.status.busy":"2023-10-20T07:58:10.972219Z","iopub.status.idle":"2023-10-20T07:58:13.188338Z","shell.execute_reply":"2023-10-20T07:58:13.187410Z","shell.execute_reply.started":"2023-10-20T07:58:10.972827Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"376980fc926f48e2bf7eb61d6c054670","version_major":2,"version_minor":0},"text/plain":["adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/internlm-7b-finetuned/commit/92d245cd0ed8e7b020a2ac2d53d102cbfe4b242b', commit_message='Upload model', commit_description='', oid='92d245cd0ed8e7b020a2ac2d53d102cbfe4b242b', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('internlm-7b-finetuned')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
