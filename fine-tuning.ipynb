{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 1. Preprocess Data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:11:32.157947Z","iopub.status.busy":"2023-10-13T02:11:32.157090Z","iopub.status.idle":"2023-10-13T02:11:42.652458Z","shell.execute_reply":"2023-10-13T02:11:42.650891Z","shell.execute_reply.started":"2023-10-13T02:11:32.157901Z"},"trusted":true},"outputs":[],"source":["!pip install gdown\n","!pip install huggingface_hub"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import gdown\n","\n","url = \"https://drive.google.com/drive/folders/1KLzX-PB_1SeufhlLrrGrArDw21F2KMgT\"\n","gdown.download_folder(url, quiet=True, use_cookies=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T02:14:25.906290Z","iopub.status.busy":"2023-10-13T02:14:25.905897Z","iopub.status.idle":"2023-10-13T02:14:27.030834Z","shell.execute_reply":"2023-10-13T02:14:27.029401Z","shell.execute_reply.started":"2023-10-13T02:14:25.906257Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["batch1\tbatch10  batch2  batch3  batch4  batch5  batch6  batch7  batch8  batch9\n"]}],"source":["%cd manual_reviewed\n","!dir\n","!rm batch1\n","!mv batch1s batch1\n","!dir"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:49:42.345598Z","iopub.status.busy":"2023-10-13T03:49:42.345080Z","iopub.status.idle":"2023-10-13T03:49:44.917072Z","shell.execute_reply":"2023-10-13T03:49:44.915844Z","shell.execute_reply.started":"2023-10-13T03:49:42.345558Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>input</th>\n","      <th>output</th>\n","      <th>instruction</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dokter, aku mengalami serangan panik tiba-tiba...</td>\n","      <td>Berdasarkan apa yang Anda katakan, sepertinya ...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Dokter, aku sudah beberapa minggu ini mengalam...</td>\n","      <td>Anda mungkin memiliki polip tali suara. Untuk ...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Halo, Dokter, aku mungkin memiliki sindrom Tur...</td>\n","      <td>Oke, dalam hal itu, Anda perlu menjalani pemer...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Dokter, aku mengalami kondisi yang disebut kri...</td>\n","      <td>Anda harus menjalani pemeriksaan kulit fisik l...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Dokter, aku pikir aku telah diracuni. Aku tida...</td>\n","      <td>Maaf mendengar itu. Kita perlu melakukan beber...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>4995</th>\n","      <td>Dokter, aku sering buang air kecil, gatal vagi...</td>\n","      <td>Berdasarkan gejala Anda, tampaknya Anda mungki...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4996</th>\n","      <td>Aku punya banyak masalah dengan buang air keci...</td>\n","      <td>Gejala ini bisa disebabkan oleh Human Papillom...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4997</th>\n","      <td>Dokter, aku mengalami buang air kecil, buang a...</td>\n","      <td>Berdasarkan gejala Anda, kemungkinan Anda memi...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4998</th>\n","      <td>Hei dokter, aku mengalami sakit lengan, sakit ...</td>\n","      <td>Berdasarkan gejala Anda, mungkin Anda memiliki...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","    <tr>\n","      <th>4999</th>\n","      <td>Dokter, aku mengalami beberapa ledakan panas, ...</td>\n","      <td>Berdasarkan gejala Anda, mungkin Anda mengalam...</td>\n","      <td>Jika Anda seorang dokter, silakan menjawab per...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                  input  \\\n","0     Dokter, aku mengalami serangan panik tiba-tiba...   \n","1     Dokter, aku sudah beberapa minggu ini mengalam...   \n","2     Halo, Dokter, aku mungkin memiliki sindrom Tur...   \n","3     Dokter, aku mengalami kondisi yang disebut kri...   \n","4     Dokter, aku pikir aku telah diracuni. Aku tida...   \n","...                                                 ...   \n","4995  Dokter, aku sering buang air kecil, gatal vagi...   \n","4996  Aku punya banyak masalah dengan buang air keci...   \n","4997  Dokter, aku mengalami buang air kecil, buang a...   \n","4998  Hei dokter, aku mengalami sakit lengan, sakit ...   \n","4999  Dokter, aku mengalami beberapa ledakan panas, ...   \n","\n","                                                 output  \\\n","0     Berdasarkan apa yang Anda katakan, sepertinya ...   \n","1     Anda mungkin memiliki polip tali suara. Untuk ...   \n","2     Oke, dalam hal itu, Anda perlu menjalani pemer...   \n","3     Anda harus menjalani pemeriksaan kulit fisik l...   \n","4     Maaf mendengar itu. Kita perlu melakukan beber...   \n","...                                                 ...   \n","4995  Berdasarkan gejala Anda, tampaknya Anda mungki...   \n","4996  Gejala ini bisa disebabkan oleh Human Papillom...   \n","4997  Berdasarkan gejala Anda, kemungkinan Anda memi...   \n","4998  Berdasarkan gejala Anda, mungkin Anda memiliki...   \n","4999  Berdasarkan gejala Anda, mungkin Anda mengalam...   \n","\n","                                            instruction  \n","0     Jika Anda seorang dokter, silakan menjawab per...  \n","1     Jika Anda seorang dokter, silakan menjawab per...  \n","2     Jika Anda seorang dokter, silakan menjawab per...  \n","3     Jika Anda seorang dokter, silakan menjawab per...  \n","4     Jika Anda seorang dokter, silakan menjawab per...  \n","...                                                 ...  \n","4995  Jika Anda seorang dokter, silakan menjawab per...  \n","4996  Jika Anda seorang dokter, silakan menjawab per...  \n","4997  Jika Anda seorang dokter, silakan menjawab per...  \n","4998  Jika Anda seorang dokter, silakan menjawab per...  \n","4999  Jika Anda seorang dokter, silakan menjawab per...  \n","\n","[5000 rows x 3 columns]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","df = pd.DataFrame()\n","\n","for i in range(10):\n","    inp = pd.read_excel(f'batch{i+1}', usecols=['input', 'output', 'instruction'])\n","    df = pd.concat([df, inp])\n","\n","df = df.reset_index(drop=True)[['input', 'output', 'instruction']]\n","df"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:50:13.526098Z","iopub.status.busy":"2023-10-13T03:50:13.525602Z","iopub.status.idle":"2023-10-13T03:50:13.535213Z","shell.execute_reply":"2023-10-13T03:50:13.533877Z","shell.execute_reply.started":"2023-10-13T03:50:13.526061Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{\"input\":\"Dokter, aku mengalami serangan panik tiba-tiba dan sering.\",\"output\":\"Berdasarkan apa yang Anda katakan, sepertinya Anda mungkin menderita gangguan panik. Langkah terbaik adalah memulai dengan psikoterapi dan konseling kesehatan mental. Selain itu, kita harus melakukan elektrokardiogram untuk memastikan bahwa tidak ada masalah fisik yang menyebabkan serangan panik Anda. Kita juga perlu melakukan skrining depresi dan skrining toksikologi untuk mengesampingkan penyebab lain. Akhirnya, saya akan merekomendasikan evaluasi dan terapi psikologis dan psikiatri yang komprehensif untuk membantu mengelola gejala Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku sudah beberapa minggu ini mengalami suara serak dan tidak kunjung membaik meskipun sudah minum obat. Apa masalahnya?\",\"output\":\"Anda mungkin memiliki polip tali suara. Untuk mengkonfirmasi ini, kita perlu melakukan trakeoskopi dan laringoskopi dengan biopsi. Kita juga mungkin perlu melakukan penilaian terapi kerja seperti terapi pidato, prosedur diagnostik lainnya seperti wawancara atau konsultasi, latihan terapi fisik, serta prosedur diagnostik di hidung, mulut, dan pharynx Anda untuk mengesampingkan kondisi lain yang mendasari. Selain itu, kita mungkin perlu mengevaluasi mata dan telinga Anda untuk kondisi terkait, seperti diagnostik ophthalmologic dan otologic dan pengobatan.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Halo, Dokter, aku mungkin memiliki sindrom Turner.\",\"output\":\"Oke, dalam hal itu, Anda perlu menjalani pemeriksaan kulit fisik lengkap, ultrasonografi, dan beberapa prosedur diagnostik lainnya seperti wawancara, evaluasi, dan konsultasi. Selain itu, kita perlu melakukan ekokardiografi, memeriksa payudara Anda, dan memeriksa mata dan telinga Anda untuk masalah apa pun. Kami juga akan melakukan pemeriksaan depresi untuk menilai kesehatan mental Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku mengalami kondisi yang disebut kriptorkidisme. testisku tidak turun dengan benar ke dalam skrotum. Apa tes medis yang perlu aku lakukan?\",\"output\":\"Anda harus menjalani pemeriksaan kulit fisik lengkap untuk melihat sejauh mana testis yang tidak turun. Kemudian, kita perlu melakukan ultrasonografi untuk mengetahui lokasi testis yang tepat. Setelah itu, pemeriksaan panggul dan pemeriksaan rektum akan dilakukan untuk menentukan apakah testis telah turun ke wilayah panggul. Jika tidak, maka prosedur terapi OR lainnya yang terkait dengan prosedur alat kelamin pria atau sistem saraf mungkin diperlukan. Kami juga akan melakukan penilaian terapi kerja untuk menilai terapi pidato Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n","{\"input\":\"Dokter, aku pikir aku telah diracuni. Aku tidak sengaja meminum etilen glikol.\",\"output\":\"Maaf mendengar itu. Kita perlu melakukan beberapa tes untuk menentukan tingkat keracunan. Kita perlu memberikan penggantian cairan intravena untuk membantu mencuci racun. Kita juga perlu melakukan tes hematologis, tes toksikologi, dan jumlah darah lengkap untuk menilai kerusakan. Selain itu, kita perlu melakukan elektrokardiogram, mengukur kadar glukosa Anda dan memeriksa tingkat alkohol darah Anda.\",\"instruction\":\"Jika Anda seorang dokter, silakan menjawab pertanyaan medis berdasarkan deskripsi pasien.\"}\n","<class 'str'>\n"]}],"source":["for i in df.index[:5]:\n","    print(df.loc[i].to_json())\n","    print(type(df.loc[i].to_json()))"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-10-13T03:51:34.277967Z","iopub.status.busy":"2023-10-13T03:51:34.277479Z","iopub.status.idle":"2023-10-13T03:51:34.880947Z","shell.execute_reply":"2023-10-13T03:51:34.879777Z","shell.execute_reply.started":"2023-10-13T03:51:34.277934Z"},"trusted":true},"outputs":[],"source":["with open('allBatch.json', 'w') as f:\n","    for i in df.index:\n","        f.writelines(df.loc[i].to_json() + '\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset json/default to /root/.cache/huggingface/datasets/json/default-ca991695af4ec410/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9da9402ab93c4697a6e167f1fbdb67f5","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4aa2bf085be74b548a44d9bf68efb6af","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset json downloaded and prepared to /root/.cache/huggingface/datasets/json/default-ca991695af4ec410/0.0.0/ac0ca5f5289a6cf108e706efcf040422dbbfa8e658dee6a819f20d76bb84d26b. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"170683d9abac42c6a92ff8d7abc57acf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['input', 'output', 'instruction'],\n","        num_rows: 5000\n","    })\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset\n","\n","# Adjust with your path\n","data = load_dataset(\"json\", data_files='/kaggle/input/allbatch/allBatch.json')\n","data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0e8500647ca4e929481f2ea588ef6a8","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["from huggingface_hub import notebook_login\n","\n","notebook_login()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. LlaMa 2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:24:53.156282Z","iopub.status.busy":"2023-10-16T01:24:53.155997Z","iopub.status.idle":"2023-10-16T01:25:42.340093Z","shell.execute_reply":"2023-10-16T01:25:42.338932Z","shell.execute_reply.started":"2023-10-16T01:24:53.156259Z"},"trusted":true},"outputs":[],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-19T04:25:48.261940Z","iopub.status.busy":"2023-10-19T04:25:48.261699Z","iopub.status.idle":"2023-10-19T04:26:03.186601Z","shell.execute_reply":"2023-10-19T04:26:03.185859Z","shell.execute_reply.started":"2023-10-19T04:25:48.261919Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:26:20.896386Z","iopub.status.busy":"2023-10-16T01:26:20.894984Z","iopub.status.idle":"2023-10-16T01:30:00.927623Z","shell.execute_reply":"2023-10-16T01:30:00.926102Z","shell.execute_reply.started":"2023-10-16T01:26:20.896344Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5aec0134d844c3fae87597838b11b3e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"efff25e0c4974260989bd8f496bdcc05","version_major":2,"version_minor":0},"text/plain":["Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"23bfd7304b96431cbd207f84f24f3771","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71b20db883f34faea182a08358763d6c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c69c166c43b422cad9f38c036c835fb","version_major":2,"version_minor":0},"text/plain":["Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b125824206c4d73a8f9be490068eed7","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e7d2a6f250664bd2b4c6b1eb719e5481","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["base_model = 'meta-llama/Llama-2-7b-hf'\n","model = LlamaForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:00.931918Z","iopub.status.busy":"2023-10-16T01:30:00.931497Z","iopub.status.idle":"2023-10-16T01:30:01.442883Z","shell.execute_reply":"2023-10-16T01:30:01.441946Z","shell.execute_reply.started":"2023-10-16T01:30:00.931880Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ccc2d21b14546409adf22a1ed7d0e74","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"59f441de57734e12bec5bf70d5f8b52c","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e446d3d584664836b4225919b33af532","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = LlamaTokenizer.from_pretrained(base_model)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.445159Z","iopub.status.busy":"2023-10-16T01:30:01.444329Z","iopub.status.idle":"2023-10-16T01:30:01.449494Z","shell.execute_reply":"2023-10-16T01:30:01.448399Z","shell.execute_reply.started":"2023-10-16T01:30:01.445114Z"},"trusted":true},"outputs":[],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    get_peft_model_state_dict,\n","    prepare_model_for_int8_training\n",")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.452470Z","iopub.status.busy":"2023-10-16T01:30:01.451841Z","iopub.status.idle":"2023-10-16T01:30:01.474831Z","shell.execute_reply":"2023-10-16T01:30:01.474037Z","shell.execute_reply.started":"2023-10-16T01:30:01.452438Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]}],"source":["model = prepare_model_for_int8_training(model)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.476354Z","iopub.status.busy":"2023-10-16T01:30:01.476063Z","iopub.status.idle":"2023-10-16T01:30:01.483061Z","shell.execute_reply":"2023-10-16T01:30:01.481617Z","shell.execute_reply.started":"2023-10-16T01:30:01.476327Z"},"trusted":true},"outputs":[],"source":["# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  target_modules=lora_target_modules,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:30:01.485272Z","iopub.status.busy":"2023-10-16T01:30:01.484596Z","iopub.status.idle":"2023-10-16T01:30:01.635870Z","shell.execute_reply":"2023-10-16T01:30:01.634925Z","shell.execute_reply.started":"2023-10-16T01:30:01.485239Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 4,194,304 || all params: 6,742,609,920 || trainable%: 0.06220594176090199\n"]}],"source":["model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:21.970880Z","iopub.status.busy":"2023-10-20T01:53:21.970297Z","iopub.status.idle":"2023-10-20T01:53:21.980240Z","shell.execute_reply":"2023-10-20T01:53:21.979084Z","shell.execute_reply.started":"2023-10-20T01:53:21.970822Z"},"trusted":true},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  if label:\n","      res = '''<s>[INST] <<SYS>>\\n{0}\\n<</SYS>>\\n\\n{1} [/INST] {2} </s>'''.format(template['prompt_input'].format(instruction=instruction, input=input), template['response_split'], label)\n","  else:\n","      res = '''<s>[INST] <<SYS>>\\n{0}\\n<</SYS>>\\n\\n{1} [/INST]'''.format(template['prompt_input'].format(instruction=instruction, input=input), template['response_split'])\n","      \n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:24.647601Z","iopub.status.busy":"2023-10-20T01:53:24.647105Z","iopub.status.idle":"2023-10-20T01:53:31.515663Z","shell.execute_reply":"2023-10-20T01:53:31.514772Z","shell.execute_reply.started":"2023-10-20T01:53:24.647559Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:16.958032Z","iopub.status.busy":"2023-10-16T01:35:16.957669Z","iopub.status.idle":"2023-10-16T01:35:16.973450Z","shell.execute_reply":"2023-10-16T01:35:16.972446Z","shell.execute_reply.started":"2023-10-16T01:35:16.958006Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:20.430557Z","iopub.status.busy":"2023-10-16T01:35:20.430118Z","iopub.status.idle":"2023-10-16T01:35:20.439721Z","shell.execute_reply":"2023-10-16T01:35:20.438457Z","shell.execute_reply.started":"2023-10-16T01:35:20.430526Z"},"trusted":true},"outputs":[],"source":["model.config.use_cache = False\n","old_state_dict = model.state_dict\n","model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(model, type(model))"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T01:35:24.349378Z","iopub.status.busy":"2023-10-16T01:35:24.349029Z","iopub.status.idle":"2023-10-16T07:36:00.092273Z","shell.execute_reply":"2023-10-16T07:36:00.091243Z","shell.execute_reply.started":"2023-10-16T01:35:24.349352Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231016_013536-k7qd287p</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/fadliaulawi/huggingface/runs/k7qd287p' target=\"_blank\">dulcet-sound-3</a></strong> to <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/fadliaulawi/huggingface/runs/k7qd287p' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface/runs/k7qd287p</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [105/105 5:56:20, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=105, training_loss=0.9756216616857619, metrics={'train_runtime': 21635.2211, 'train_samples_per_second': 0.624, 'train_steps_per_second': 0.005, 'total_flos': 1.3639486365892608e+17, 'train_loss': 0.9756216616857619, 'epoch': 2.99})"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-10-16T07:40:32.041087Z","iopub.status.busy":"2023-10-16T07:40:32.040677Z","iopub.status.idle":"2023-10-16T07:40:32.892982Z","shell.execute_reply":"2023-10-16T07:40:32.891851Z","shell.execute_reply.started":"2023-10-16T07:40:32.041058Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eae36e01d3b5485f8bd7c7c9edea020e","version_major":2,"version_minor":0},"text/plain":["adapter_model.safetensors:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/Llama-2-7b-finetuned-2/commit/65144b5fae005bb987602fa9a6cf9102284a7271', commit_message='Upload model', commit_description='', oid='65144b5fae005bb987602fa9a6cf9102284a7271', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('Llama-2-7b-finetuned-2', safe_serialization=True)"]},{"cell_type":"markdown","metadata":{},"source":["# PolyLM"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:29:03.799964Z","iopub.status.busy":"2023-10-20T01:29:03.799292Z","iopub.status.idle":"2023-10-20T01:29:42.070857Z","shell.execute_reply":"2023-10-20T01:29:42.069976Z","shell.execute_reply.started":"2023-10-20T01:29:03.799939Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'alpaca-lora'...\n","remote: Enumerating objects: 607, done.\u001b[K\n","remote: Total 607 (delta 0), reused 0 (delta 0), pack-reused 607\u001b[K\n","Receiving objects: 100% (607/607), 27.84 MiB | 19.27 MiB/s, done.\n","Resolving deltas: 100% (357/357), done.\n","Collecting git+https://github.com/huggingface/peft.git (from -r alpaca-lora/requirements.txt (line 9))\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-pcbcvtrq\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-pcbcvtrq\n","  Resolved https://github.com/huggingface/peft.git to commit 56556faa17263be8ef1802c172141705b71c28dc\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 1)) (0.22.0)\n","Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 2)) (1.4.4)\n","Collecting loralib (from -r alpaca-lora/requirements.txt (line 3))\n","  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n","Collecting bitsandbytes (from -r alpaca-lora/requirements.txt (line 4))\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting black (from -r alpaca-lora/requirements.txt (line 5))\n","  Downloading black-23.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 7)) (2.1.0)\n","Collecting fire (from -r alpaca-lora/requirements.txt (line 8))\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: transformers>=4.28.0 in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 10)) (4.33.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 11)) (0.1.99)\n","Collecting gradio (from -r alpaca-lora/requirements.txt (line 12))\n","  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (8.1.7)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (1.0.0)\n","Collecting packaging>=20.0 (from accelerate->-r alpaca-lora/requirements.txt (line 1))\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pathspec>=0.9.0 (from black->-r alpaca-lora/requirements.txt (line 5))\n","  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n","Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (3.10.0)\n","Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (4.6.3)\n","Requirement already satisfied: ipython>=7.8.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (8.14.0)\n","Collecting tokenize-rt>=3.2.0 (from black->-r alpaca-lora/requirements.txt (line 5))\n","  Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.16.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.18.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (2.3.0)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0->-r alpaca-lora/requirements.txt (line 9)) (0.3.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (0.13.3)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (22.1.0)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.98.0)\n","Collecting ffmpy (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gradio-client==0.6.1 (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (5.12.0)\n","Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.7.2)\n","Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.9.1)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (9.5.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (1.10.9)\n","Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.25.1)\n","Collecting python-multipart (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.22.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (11.0.3)\n","Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (4.17.3)\n","Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.12.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.1)\n","Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.18.2)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.1.6)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (3.0.38)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (2.15.1)\n","Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.9.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (4.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.4.4)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.3)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.7.22)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.14.0)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.27.0)\n","Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.3.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.7.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.8.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.19.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.6)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (2.2.1)\n","Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.1.1)\n","Building wheels for collected packages: fire, peft, ffmpy\n","  Building wheel for fire (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=8d9a734873fd34589b1187d3b717d2846b198157e5b92e7f6c7d6a7609c751c1\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=124303 sha256=5ae9f459ecc570523d264a9efdd5e390b394d970105bac2472f6e66e9af67006\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i9rr96pq/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=644f2b378bd45150f58385faf0c149f9230916cd9073b1db66a5c81ee6d87526\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built fire peft ffmpy\n","Installing collected packages: ffmpy, bitsandbytes, tokenize-rt, semantic-version, python-multipart, pathspec, packaging, loralib, fire, httpcore, black, httpx, peft, gradio-client, gradio\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.41.1 black-23.10.0 ffmpy-0.3.1 fire-0.5.0 gradio-3.50.2 gradio-client-0.6.1 httpcore-0.18.0 httpx-0.25.0 loralib-0.1.2 packaging-23.2 pathspec-0.11.2 peft-0.6.0.dev0 python-multipart-0.0.6 semantic-version-2.10.0 tokenize-rt-5.2.0\n"]}],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:43:13.460279Z","iopub.status.busy":"2023-10-18T06:43:13.459895Z","iopub.status.idle":"2023-10-18T06:44:04.773827Z","shell.execute_reply":"2023-10-18T06:44:04.769985Z","shell.execute_reply.started":"2023-10-18T06:43:13.460252Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"506a8dee9a124c81aeb48204eebbd0ef","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/766 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b491dbf8b1694751a2a6e59e0583aa35","version_major":2,"version_minor":0},"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/3.68G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch\n","\n","base_model = 'DAMO-NLP-MT/polylm-1.7b'\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\"\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:44:04.778248Z","iopub.status.busy":"2023-10-18T06:44:04.777709Z","iopub.status.idle":"2023-10-18T06:44:06.658257Z","shell.execute_reply":"2023-10-18T06:44:06.657483Z","shell.execute_reply.started":"2023-10-18T06:44:04.778222Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d800a10f3f34a29be1042f58230ac7f","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"233c480d39ea42c1ac8c185c17d58ab3","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/4.75M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"349cf06ee4fc4407ac2291ad737a13bc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:44:14.521776Z","iopub.status.busy":"2023-10-18T06:44:14.521206Z","iopub.status.idle":"2023-10-18T06:44:14.607042Z","shell.execute_reply":"2023-10-18T06:44:14.606294Z","shell.execute_reply.started":"2023-10-18T06:44:14.521749Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainable params: 1,572,864 || all params: 1,738,657,792 || trainable%: 0.09046426543723217\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]}],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training\n",")\n","\n","model = prepare_model_for_int8_training(model)\n","\n","# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n","\n","  if label:\n","      res = f\"{res} \\n\\n### Tanggapan:\\n{label}\"\n","\n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:45:17.061772Z","iopub.status.busy":"2023-10-18T06:45:17.061110Z","iopub.status.idle":"2023-10-18T06:45:17.078327Z","shell.execute_reply":"2023-10-18T06:45:17.077539Z","shell.execute_reply.started":"2023-10-18T06:45:17.061741Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T06:45:20.980715Z","iopub.status.busy":"2023-10-18T06:45:20.980358Z","iopub.status.idle":"2023-10-18T08:05:06.397778Z","shell.execute_reply":"2023-10-18T08:05:06.397103Z","shell.execute_reply.started":"2023-10-18T06:45:20.980688Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231018_064533-dyb2svwi</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/fadliaulawi/huggingface/runs/dyb2svwi' target=\"_blank\">feasible-grass-7</a></strong> to <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/fadliaulawi/huggingface/runs/dyb2svwi' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface/runs/dyb2svwi</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [105/105 1:18:15, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=105, training_loss=2.7755213919140043, metrics={'train_runtime': 4784.9242, 'train_samples_per_second': 2.821, 'train_steps_per_second': 0.022, 'total_flos': 2.100942098399232e+16, 'train_loss': 2.7755213919140043, 'epoch': 2.99})"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-10-18T08:10:55.898499Z","iopub.status.busy":"2023-10-18T08:10:55.897824Z","iopub.status.idle":"2023-10-18T08:10:58.221243Z","shell.execute_reply":"2023-10-18T08:10:58.220612Z","shell.execute_reply.started":"2023-10-18T08:10:55.898468Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42a1e157511b4e569f821babc64fb102","version_major":2,"version_minor":0},"text/plain":["adapter_model.bin:   0%|          | 0.00/6.31M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/polylm-1.7b-finetuned/commit/5385485e8e489c405600862be285673f51cc3f0b', commit_message='Upload model', commit_description='', oid='5385485e8e489c405600862be285673f51cc3f0b', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('polylm-1.7b-finetuned')"]},{"cell_type":"markdown","metadata":{},"source":["# InternLM"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'alpaca-lora'...\n","remote: Enumerating objects: 607, done.\u001b[K\n","remote: Total 607 (delta 0), reused 0 (delta 0), pack-reused 607\u001b[K\n","Receiving objects: 100% (607/607), 27.84 MiB | 19.27 MiB/s, done.\n","Resolving deltas: 100% (357/357), done.\n","Collecting git+https://github.com/huggingface/peft.git (from -r alpaca-lora/requirements.txt (line 9))\n","  Cloning https://github.com/huggingface/peft.git to /tmp/pip-req-build-pcbcvtrq\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/peft.git /tmp/pip-req-build-pcbcvtrq\n","  Resolved https://github.com/huggingface/peft.git to commit 56556faa17263be8ef1802c172141705b71c28dc\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 1)) (0.22.0)\n","Requirement already satisfied: appdirs in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 2)) (1.4.4)\n","Collecting loralib (from -r alpaca-lora/requirements.txt (line 3))\n","  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n","Collecting bitsandbytes (from -r alpaca-lora/requirements.txt (line 4))\n","  Downloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting black (from -r alpaca-lora/requirements.txt (line 5))\n","  Downloading black-23.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 7)) (2.1.0)\n","Collecting fire (from -r alpaca-lora/requirements.txt (line 8))\n","  Downloading fire-0.5.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: transformers>=4.28.0 in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 10)) (4.33.0)\n","Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from -r alpaca-lora/requirements.txt (line 11)) (0.1.99)\n","Collecting gradio (from -r alpaca-lora/requirements.txt (line 12))\n","  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (21.3)\n","Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (5.9.3)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (6.0)\n","Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate->-r alpaca-lora/requirements.txt (line 1)) (2.0.0)\n","Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (8.1.7)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (1.0.0)\n","Collecting packaging>=20.0 (from accelerate->-r alpaca-lora/requirements.txt (line 1))\n","  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pathspec>=0.9.0 (from black->-r alpaca-lora/requirements.txt (line 5))\n","  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n","Requirement already satisfied: platformdirs>=2 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (3.10.0)\n","Requirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (2.0.1)\n","Requirement already satisfied: typing-extensions>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (4.6.3)\n","Requirement already satisfied: ipython>=7.8.0 in /opt/conda/lib/python3.10/site-packages (from black->-r alpaca-lora/requirements.txt (line 5)) (8.14.0)\n","Collecting tokenize-rt>=3.2.0 (from black->-r alpaca-lora/requirements.txt (line 5))\n","  Downloading tokenize_rt-5.2.0-py2.py3-none-any.whl (5.8 kB)\n","Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (11.0.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.3.7)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.16.4)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->-r alpaca-lora/requirements.txt (line 7)) (0.18.0)\n","Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (1.16.0)\n","Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire->-r alpaca-lora/requirements.txt (line 8)) (2.3.0)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.6.0.dev0->-r alpaca-lora/requirements.txt (line 9)) (0.3.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.28.0->-r alpaca-lora/requirements.txt (line 10)) (0.13.3)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (22.1.0)\n","Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (5.1.1)\n","Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.98.0)\n","Collecting ffmpy (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting gradio-client==0.6.1 (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpx (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading httpx-0.25.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.7/75.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (5.12.0)\n","Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.1.2)\n","Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (2.1.3)\n","Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.7.2)\n","Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (3.9.1)\n","Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (9.5.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (1.10.9)\n","Requirement already satisfied: pydub in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.25.1)\n","Collecting python-multipart (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (0.22.0)\n","Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.10/site-packages (from gradio->-r alpaca-lora/requirements.txt (line 12)) (11.0.3)\n","Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (4.17.3)\n","Requirement already satisfied: toolz in /opt/conda/lib/python3.10/site-packages (from altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.12.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.3.1)\n","Requirement already satisfied: backcall in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.0)\n","Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.1.1)\n","Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.18.2)\n","Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.1.6)\n","Requirement already satisfied: pickleshare in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (3.0.38)\n","Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (2.15.1)\n","Requirement already satisfied: stack-data in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.6.2)\n","Requirement already satisfied: traitlets>=5 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (5.9.0)\n","Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (4.8.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.1.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (4.40.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.4.4)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib~=3.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.3)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets->-r alpaca-lora/requirements.txt (line 7)) (2023.7.22)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (3.1)\n","Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.14.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.14.0)\n","Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from fastapi->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.27.0)\n","Collecting httpcore<0.19.0,>=0.18.0 (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12))\n","  Downloading httpcore-0.18.0-py3-none-any.whl (76 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.0/76.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.3.0)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.19.0,>=0.18.0->httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (3.7.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.8.3)\n","Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r alpaca-lora/requirements.txt (line 12)) (0.19.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.7.0)\n","Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.6)\n","Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (1.2.0)\n","Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (2.2.1)\n","Requirement already satisfied: pure-eval in /opt/conda/lib/python3.10/site-packages (from stack-data->ipython>=7.8.0->black->-r alpaca-lora/requirements.txt (line 5)) (0.2.2)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate->-r alpaca-lora/requirements.txt (line 1)) (1.3.0)\n","Requirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5.0,>=3.0->httpcore<0.19.0,>=0.18.0->httpx->gradio->-r alpaca-lora/requirements.txt (line 12)) (1.1.1)\n","Building wheels for collected packages: fire, peft, ffmpy\n","  Building wheel for fire (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=8d9a734873fd34589b1187d3b717d2846b198157e5b92e7f6c7d6a7609c751c1\n","  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n","  Building wheel for peft (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for peft: filename=peft-0.6.0.dev0-py3-none-any.whl size=124303 sha256=5ae9f459ecc570523d264a9efdd5e390b394d970105bac2472f6e66e9af67006\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-i9rr96pq/wheels/d7/c7/de/1368fac8590e1b103ddc2ec2a28ad51d83aded1a3830e8a087\n","  Building wheel for ffmpy (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=644f2b378bd45150f58385faf0c149f9230916cd9073b1db66a5c81ee6d87526\n","  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n","Successfully built fire peft ffmpy\n","Installing collected packages: ffmpy, bitsandbytes, tokenize-rt, semantic-version, python-multipart, pathspec, packaging, loralib, fire, httpcore, black, httpx, peft, gradio-client, gradio\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.2 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","jupyterlab-lsp 4.2.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","momepy 0.6.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.9.0 which is incompatible.\n","ydata-profiling 4.3.1 requires scipy<1.11,>=1.4.1, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed bitsandbytes-0.41.1 black-23.10.0 ffmpy-0.3.1 fire-0.5.0 gradio-3.50.2 gradio-client-0.6.1 httpcore-0.18.0 httpx-0.25.0 loralib-0.1.2 packaging-23.2 pathspec-0.11.2 peft-0.6.0.dev0 python-multipart-0.0.6 semantic-version-2.10.0 tokenize-rt-5.2.0\n"]}],"source":["!git clone https://github.com/tloen/alpaca-lora\n","!pip install -r alpaca-lora/requirements.txt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:29:42.072688Z","iopub.status.busy":"2023-10-20T01:29:42.072425Z","iopub.status.idle":"2023-10-20T01:51:18.213140Z","shell.execute_reply":"2023-10-20T01:51:18.212381Z","shell.execute_reply.started":"2023-10-20T01:29:42.072663Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90292abace264fed9a521c9f10674dd2","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/731 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ecefb177c4347b896331ada018d7602","version_major":2,"version_minor":0},"text/plain":["Downloading (…)guration_internlm.py:   0%|          | 0.00/5.18k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- configuration_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ba18541584d149f3985a514f9f5658f1","version_major":2,"version_minor":0},"text/plain":["Downloading (…)modeling_internlm.py:   0%|          | 0.00/43.7k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- modeling_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"220bc725e99a452cadda39455ae8bd73","version_major":2,"version_minor":0},"text/plain":["Downloading (…)model.bin.index.json:   0%|          | 0.00/37.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6300c6a27752490297a3429d12000231","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3b5baaa87aeb40e387ffbb2723812c6d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00001-of-00008.bin:   0%|          | 0.00/1.97G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5c6d9d76f424823babc200ba5037707","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00002-of-00008.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dca19a4c573a4ff78ebe92fd915797fd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00003-of-00008.bin:   0%|          | 0.00/1.93G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d9bc9e500a840dcacd595c01c8ee783","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00004-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f01901a07953472fa80a5c18896ec7db","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00005-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac30a5e5b9454decb4777eb55a386773","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00006-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"324bb0fd0580442eabb7d69860d15f5e","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00007-of-00008.bin:   0%|          | 0.00/1.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7597b88c09974cf9ab380ab10327be77","version_major":2,"version_minor":0},"text/plain":["Downloading (…)l-00008-of-00008.bin:   0%|          | 0.00/845M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0e0d791f4eca48cda7abce77c9ff7a5f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0b7dcc563df4f1aa7377fc77af02750","version_major":2,"version_minor":0},"text/plain":["Downloading (…)neration_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments, DataCollatorForSeq2Seq\n","import torch\n","\n","base_model = 'internlm/internlm-7b'\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    load_in_8bit=True,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    trust_remote_code=True\n",")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:01.614177Z","iopub.status.busy":"2023-10-20T01:53:01.612774Z","iopub.status.idle":"2023-10-20T01:53:03.649251Z","shell.execute_reply":"2023-10-20T01:53:03.648520Z","shell.execute_reply.started":"2023-10-20T01:53:01.614143Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fb1725fe02454277b95cbabf0a3c496b","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/343 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ec1c659fe134e2f8b0434b4150114a3","version_major":2,"version_minor":0},"text/plain":["Downloading (…)nization_internlm.py:   0%|          | 0.00/8.95k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["A new version of the following files was downloaded from https://huggingface.co/internlm/internlm-7b:\n","- tokenization_internlm.py\n",". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1152678963024ece91e933ec4edca8ec","version_major":2,"version_minor":0},"text/plain":["Downloading tokenizer.model:   0%|          | 0.00/1.66M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a87b5ece75f54646ae26ab473e1c0abd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/95.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenizer = AutoTokenizer.from_pretrained(base_model, trust_remote_code=True)\n","tokenizer.pad_token_id = (0)  # unk. we want this to be different from the eos token\n","tokenizer.padding_side = \"left\"  # Allow batched inference"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:06.684764Z","iopub.status.busy":"2023-10-20T01:53:06.684433Z","iopub.status.idle":"2023-10-20T01:53:06.971209Z","shell.execute_reply":"2023-10-20T01:53:06.970385Z","shell.execute_reply.started":"2023-10-20T01:53:06.684739Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:107: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["trainable params: 4,194,304 || all params: 7,326,142,464 || trainable%: 0.05725119352524783\n"]}],"source":["from peft import (\n","    LoraConfig,\n","    get_peft_model,\n","    prepare_model_for_int8_training\n",")\n","\n","model = prepare_model_for_int8_training(model)\n","\n","# Lora parameters\n","lora_r = 8\n","lora_alpha = 16\n","lora_target_modules = [\"q_proj\", \"v_proj\"]\n","lora_dropout = 0.05\n","\n","config = LoraConfig(\n","  r=lora_r,\n","  lora_alpha=lora_alpha,\n","  target_modules=lora_target_modules,\n","  lora_dropout=lora_dropout,\n","  bias=\"none\",\n","  task_type=\"CAUSAL_LM\",\n",")\n","\n","model = get_peft_model(model, config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_prompt(\n","    instruction, input, label\n","):\n","  template = {\n","      \"prompt_input\": \"Di bawah ini adalah instruksi yang menjelaskan tugas, dipasangkan dengan masukan yang memberikan konteks lebih lanjut. Tulis tanggapan yang melengkapi permintaan dengan tepat.\\n\\n### Instruksi:\\n{instruction}\\n\\n### Masukan:\\n{input}\",\n","      \"response_split\": \"### Tanggapan:\"\n","  }\n","\n","  res = template[\"prompt_input\"].format(instruction=instruction, input=input)\n","\n","  if label:\n","      res = f\"{res} \\n\\n### Tanggapan:\\n{label}\"\n","\n","  return res\n","\n","def generate_and_tokenize_prompt(data_point):\n","    full_prompt = generate_prompt(\n","        data_point[\"instruction\"],\n","        data_point[\"input\"],\n","        data_point[\"output\"],\n","    )\n","\n","    cutoff_len = 256\n","    result = tokenizer(\n","        full_prompt,\n","        truncation=True,\n","        max_length=cutoff_len,\n","        padding=False,\n","        return_tensors=None,\n","    )\n","\n","    if (result[\"input_ids\"][-1] != tokenizer.eos_token_id and len(result[\"input_ids\"]) < cutoff_len):\n","        result[\"input_ids\"].append(tokenizer.eos_token_id)\n","        result[\"attention_mask\"].append(1)\n","\n","    result[\"labels\"] = result[\"input_ids\"].copy()\n","\n","    tokenized_full_prompt = result\n","\n","\n","    return tokenized_full_prompt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"92dee7ea1c75450ab2d933f8cee60294","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/4500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"15c207c6b4024328a15106b4343a0b7e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/500 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["Dataset({\n","    features: ['input', 'output', 'instruction', 'input_ids', 'attention_mask', 'labels'],\n","    num_rows: 4500\n","})"]},"metadata":{},"output_type":"display_data"}],"source":["train_val = data[\"train\"].train_test_split(test_size=0.1, shuffle=True, seed=42)\n","train_data = (train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt))\n","val_data = (train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)) #Set to 500 out from 5000\n","train_data"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:47.033523Z","iopub.status.busy":"2023-10-20T01:53:47.032840Z","iopub.status.idle":"2023-10-20T01:53:47.067267Z","shell.execute_reply":"2023-10-20T01:53:47.066418Z","shell.execute_reply.started":"2023-10-20T01:53:47.033488Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","micro_batch_size = 4\n","gradient_accumulation_steps = batch_size / micro_batch_size\n","num_epochs = 3\n","learning_rate = 3e-4\n","val_set_size = 2\n","output_dir = './result'\n","group_by_length = False\n","\n","trainer = Trainer(\n","  model=model,\n","  train_dataset=train_data,\n","  eval_dataset=val_data,\n","  args=TrainingArguments(\n","      per_device_train_batch_size=micro_batch_size,\n","      gradient_accumulation_steps=gradient_accumulation_steps,\n","      warmup_steps=100,\n","      num_train_epochs=num_epochs,\n","      learning_rate=learning_rate,\n","      fp16=True,\n","      logging_steps=10,\n","      optim=\"adamw_torch\",\n","      evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n","      save_strategy=\"steps\",\n","      eval_steps=200 if val_set_size > 0 else None,\n","      save_steps=200,\n","      output_dir=output_dir,\n","      save_total_limit=3,\n","      load_best_model_at_end=True if val_set_size > 0 else False,\n","      ddp_find_unused_parameters=None,\n","      group_by_length=group_by_length\n","),\n","  data_collator=DataCollatorForSeq2Seq(\n","      tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n","  ),\n",")"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T01:53:49.758885Z","iopub.status.busy":"2023-10-20T01:53:49.758080Z","iopub.status.idle":"2023-10-20T07:46:41.508183Z","shell.execute_reply":"2023-10-20T07:46:41.507245Z","shell.execute_reply.started":"2023-10-20T01:53:49.758853Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.15.12 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.15.9"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20231020_015401-vf0bzo5u</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/fadliaulawi/huggingface/runs/vf0bzo5u' target=\"_blank\">stellar-moon-10</a></strong> to <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/fadliaulawi/huggingface' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/fadliaulawi/huggingface/runs/vf0bzo5u' target=\"_blank\">https://wandb.ai/fadliaulawi/huggingface/runs/vf0bzo5u</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py:322: UserWarning: MatMul8bitLt: inputs will be cast from torch.float32 to float16 during quantization\n","  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [105/105 5:48:51, Epoch 2/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=105, training_loss=1.4831590016682943, metrics={'train_runtime': 21171.1265, 'train_samples_per_second': 0.638, 'train_steps_per_second': 0.005, 'total_flos': 1.384349513660498e+17, 'train_loss': 1.4831590016682943, 'epoch': 2.99})"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["model = torch.compile(model)\n","trainer.train()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-10-20T07:58:10.972856Z","iopub.status.busy":"2023-10-20T07:58:10.972219Z","iopub.status.idle":"2023-10-20T07:58:13.188338Z","shell.execute_reply":"2023-10-20T07:58:13.187410Z","shell.execute_reply.started":"2023-10-20T07:58:10.972827Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"376980fc926f48e2bf7eb61d6c054670","version_major":2,"version_minor":0},"text/plain":["adapter_model.bin:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/fadliaulawi/internlm-7b-finetuned/commit/92d245cd0ed8e7b020a2ac2d53d102cbfe4b242b', commit_message='Upload model', commit_description='', oid='92d245cd0ed8e7b020a2ac2d53d102cbfe4b242b', pr_url=None, pr_revision=None, pr_num=None)"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model.push_to_hub('internlm-7b-finetuned')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
